# AI-FACT
In the context of the course FACT in AI at the Universiteit van Amsterdam (UvA), we attempted to reproduce a paper on confidentiality in AI. The paper reproduced in this repository is *Interpretable Complex-Valued Neural Networks for Privacy Protection* by [Xiang et. al](https://arxiv.org/abs/1901.09546#:~:text=Interpretable%20Complex%2DValued%20Neural%20Networks%20for%20Privacy%20Protection,-Liyao%20Xiang%2C%20Haotian&text=Previous%20studies%20have%20found%20that,without%20too%20much%20accuracy%20degradation.). Their paper provides a framework in which part of the AI processing can be moved from the device to the cloud without the loss of confidentiality due to adversarial attacks. 

*TODO: stukje over wat er precies in de github staat*

## Prerequisites
* Anaconda. Available at: https://www.anaconda.com/distribution/

*TODO: lijst van prerequisites, waarschijnlijk alleen anaconda*

## Getting started
*TODO: uitleggen hoe je de environment opstart en hoe je start*

## Running the experiments
*TODO: uitleggen hoe je de experimenten runt en welke argumenten de main.py accepteert*

## Authors
* Luuk Kaandorp - luuk.kaandorp@student.uva.nl
* Ward Pennink - ward.pennink@student.uva.nl
* Ramon Dijkstra - ramon.dijkstra@student.uva.nl
* Reinier Bekkenutte - reinier.bekkenutte@student.uva.nl

## Acknowledgements
*TODO: acknowledgements als die er zijn*
